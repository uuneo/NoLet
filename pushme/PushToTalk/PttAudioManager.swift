//
// PttAudioManager.swift
//  pushme
//
//  Created by lynn on 2025/8/21.
//

import AVKit
import Defaults
import Opus

class PttAudioManager {
    static let shared = PttAudioManager()

    // MARK: - æ’­æ”¾å™¨

    private let playerEngine = AVAudioEngine()
    private let playerNode = AVAudioPlayerNode()
    private let EQ = AVAudioUnitEQ(numberOfBands: 2)
    private var mixer: AVAudioMixerNode = AVAudioMixerNode()
    private let format = AVAudioFormat(standardFormatWithSampleRate: 48000, channels: 1)!

    // MARK: - å½•éŸ³

    private let recordEngine = AVAudioEngine()
    private var oggWriter = OggOpusWriter()
    private var dataItem = DataItem()
    private var audioBuffer = Data()

    // MARK: - other

    private var callback: ((Double, Double) -> Void)?
    private var sessionInterrupted: ((InterruptedType) -> Void)?
    private var soundID: SystemSoundID = 0
    private var hasMicrophonePermission: Bool = false
    private init() {
        if !hasMicrophonePermission {
            requestMicrophonePermission()
        }
        // Band 1: æå‡äººå£°æ¸…æ™°åº¦ï¼ˆ2kHzï¼‰
        let band1 = EQ.bands[0]
        band1.filterType = .parametric
        band1.frequency = 2000
        band1.bandwidth = 1.5
        band1.gain = 10.0
        band1.bypass = false

        // Band 2: - å‡å°‘ä½é¢‘æ‚éŸ³ï¼ˆä½åˆ‡ï¼‰
        let band2 = EQ.bands[1]
        band2.filterType = .highPass
        band2.frequency = 100
        band2.bandwidth = 0.5
        band2.bypass = false
        EQ.globalGain = Float(Defaults[.pttVoiceVolume] * 15)

        playerEngine.attach(playerNode)
        playerEngine.attach(EQ)
        playerEngine.connect(playerNode, to: EQ, format: format)
        playerEngine.connect(EQ, to: playerEngine.mainMixerNode, format: format)
        playerEngine.prepare()

        // æ³¨å†Œé€šçŸ¥
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleInterruption(_:)),
            name: AVAudioSession.interruptionNotification,
            object: AVAudioSession.sharedInstance()
        )
    }

    deinit {
        NotificationCenter.default.removeObserver(self)
    }

    func setInterrupted(callback: @escaping (InterruptedType) -> Void) {
        sessionInterrupted = callback
    }

    func setCallback(callback: @escaping (Double, Double) -> Void) {
        self.callback = callback
    }

    // MARK: - player

    func play(filePath: URL) async throws {
        if !playerEngine.isRunning {
            try playerEngine.start()
        }

        let audioFile = try AVAudioFile(forReading: filePath)

        let asset = AVURLAsset(url: filePath)
        let duration = try? await asset.load(.duration)

        playerNode.removeTap(onBus: 0)
        playerNode.installTap(onBus: 0, bufferSize: 4096, format: nil) { _, _ in

            var currentTime: Double {
                if let nodeTime = self.playerNode.lastRenderTime,
                   let playerTime = self.playerNode.playerTime(forNodeTime: nodeTime) {
                    let seconds = Double(playerTime.sampleTime) / playerTime.sampleRate
                    return seconds
                }
                return 0
            }

            let duration = CMTimeGetSeconds(duration ?? .zero)

            self.callback?(currentTime + duration * 0.05, duration)
        }

        playerNode.play()

        _ = await playerNode.scheduleFile(audioFile, at: nil, completionCallbackType: .dataPlayedBack)

        NLog.error("æ’­æ”¾æˆåŠŸ")
    }

    func stop() {
        playerNode.removeTap(onBus: 0)
        playerNode.stop()
    }

    func setVolume(_ value: Float) {
        EQ.globalGain = value
    }

    // MARK: - å½•éŸ³

    func record() throws {
        let input = recordEngine.inputNode
        let format = input.inputFormat(forBus: 0)

        oggWriter = OggOpusWriter()
        dataItem = DataItem()
        oggWriter.inputSampleRate = Int32(format.sampleRate)
        oggWriter.begin(with: dataItem)

        input.removeTap(onBus: 0)
        guard format.sampleRate > 0 else { return }
        input.installTap(onBus: 0, bufferSize: 1024, format: format) { buffer, _ in

            let elapsedTime = self.oggWriter.encodedDuration()

            if elapsedTime > 60 { return }

            self.processAndDisposeAudioBuffer(buffer)

            let mic = self.calculateLevelPercentage(from: buffer)
            self.callback?(mic, elapsedTime)
        }

        try recordEngine.start()
        NLog.log("ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆAGC å·²å¯ç”¨ï¼‰")
    }

    func end() -> Data? {
        guard recordEngine.isRunning else { return nil }
        recordEngine.inputNode.removeTap(onBus: 0)
        recordEngine.stop()

        if oggWriter.writeFrame(nil, frameByteCount: 0),
           oggWriter.encodedDuration() > 0.2 {
            return dataItem.data()
        }

        return nil
    }

    private func processAndDisposeAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let bufferData = conversionFloat32ToInt16Buffer(buffer) else { return }
        let buffer = bufferData.audioBufferList.pointee.mBuffers

        let sampleRate = 16000
        let frameDurationMs = 60
        let bytesPerSample = 2
        let encoderPacketSizeInBytes = sampleRate * frameDurationMs / 1000 * bytesPerSample

        let currentEncoderPacket = malloc(encoderPacketSizeInBytes)!
        defer { free(currentEncoderPacket) }

        var bufferOffset = 0

        while true {
            var currentEncoderPacketSize = 0

            while currentEncoderPacketSize < encoderPacketSizeInBytes {
                if audioBuffer.count != 0 {
                    let takenBytes = min(audioBuffer.count, encoderPacketSizeInBytes - currentEncoderPacketSize)
                    if takenBytes != 0 {
                        audioBuffer.withUnsafeBytes { rawBytes in
                            let bytes = rawBytes.baseAddress!.assumingMemoryBound(to: Int8.self)

                            memcpy(currentEncoderPacket.advanced(by: currentEncoderPacketSize), bytes, takenBytes)
                        }
                        audioBuffer.replaceSubrange(0 ..< takenBytes, with: Data())
                        currentEncoderPacketSize += takenBytes
                    }
                } else if bufferOffset < Int(buffer.mDataByteSize) {
                    let takenBytes = min(Int(buffer.mDataByteSize) - bufferOffset, encoderPacketSizeInBytes - currentEncoderPacketSize)
                    if takenBytes != 0 {
                        memcpy(currentEncoderPacket.advanced(by: currentEncoderPacketSize), buffer.mData?.advanced(by: bufferOffset), takenBytes)

                        bufferOffset += takenBytes
                        currentEncoderPacketSize += takenBytes
                    }
                } else {
                    break
                }
            }

            if currentEncoderPacketSize < encoderPacketSizeInBytes {
                audioBuffer.append(currentEncoderPacket.assumingMemoryBound(to: UInt8.self), count: currentEncoderPacketSize)
                break
            } else {
                oggWriter.writeFrame(currentEncoderPacket.assumingMemoryBound(to: UInt8.self), frameByteCount: UInt(currentEncoderPacketSize))
            }
        }
    }

    func conversionFloat32ToInt16Buffer(_ buffer: AVAudioPCMBuffer) -> AVAudioPCMBuffer? {
        guard let format = AVAudioFormat(commonFormat: .pcmFormatInt16,
                                         sampleRate: buffer.format.sampleRate,
                                         channels: buffer.format.channelCount,
                                         interleaved: true) else {
            return nil
        }

        let frameLength = buffer.frameLength
        guard let convertedBuffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameLength) else {
            return nil
        }
        convertedBuffer.frameLength = frameLength

        // è·å–è¾“å…¥ float32 æ ·æœ¬æŒ‡é’ˆ
        guard let sourcePointer = buffer.floatChannelData?[0] else {
            return nil
        }

        // è·å–ç›®æ ‡ int16 æ ·æœ¬æŒ‡é’ˆ
        guard let destinationPointer = convertedBuffer.int16ChannelData?[0] else {
            return nil
        }

        for index in 0 ..< Int(frameLength) {
            let floatSample = min(max(sourcePointer[index], -1.0), 1.0)
            destinationPointer[index] = Int16(clamping: Int(floatSample * 32767.0))
        }

        return convertedBuffer
    }

    // MARK: - OTHER

    func playTips(_ fileName: TipsSound, fileExtension: String = "aac", complete: (() -> Void)? = nil) {
        setCategory(true, .playAndRecord, mode: .default)
        guard let url = Bundle.main.url(forResource: fileName.rawValue, withExtension: fileExtension) else { return }
        // å…ˆé‡Šæ”¾ä¹‹å‰çš„ SystemSoundIDï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œé¿å…å†…å­˜æ³„æ¼æˆ–é‡å¤æ’­æ”¾
        AudioServicesDisposeSystemSoundID(soundID)

        AudioServicesCreateSystemSoundID(url as CFURL, &soundID)
        // æ’­æ”¾éŸ³é¢‘ï¼Œæ’­æ”¾å®Œæˆåæ‰§è¡Œå›è°ƒ
        AudioServicesPlaySystemSoundWithCompletion(soundID) {
            // é‡Šæ”¾èµ„æº
            AudioServicesDisposeSystemSoundID(self.soundID)
            // é‡ç½®æ’­æ”¾çŠ¶æ€
            self.soundID = 0
            complete?()
        }
    }

    // MARK: - OTHER

    func calculateLevelPercentage(from buffer: AVAudioPCMBuffer) -> Double {
        guard let channelData = buffer.floatChannelData else {
            return 0.0
        }

        let channelDataValue = channelData.pointee
        // 4
        let channelDataValueArray = stride(
            from: 0,
            to: Int(buffer.frameLength),
            by: buffer.stride)
            .map { channelDataValue[$0] }

        // 5
        let rms = sqrt(channelDataValueArray.map {
            $0 * $0
        }
        .reduce(0, +) / Float(buffer.frameLength))

        // 6
        let avgPower = 20 * log10(rms)
        // 7
        let meterLevel = scaledPower(power: avgPower)

        return Double(meterLevel)
    }

    func scaledPower(power: Float) -> Float {
        // 1. é¿å… NaN æˆ– Inf
        guard power.isFinite else {
            return 0.0
        }

        // å‚è€ƒçš„æœ€å°åˆ†è´å€¼ï¼ˆé™éŸ³é˜ˆå€¼ï¼‰
        let minDb: Float = -80.0

        // 2. å°äºé˜ˆå€¼ç›´æ¥å½“ä½œé™éŸ³
        if power < minDb {
            return 0.0
        }

        // 3. å¦‚æœè¶…è¿‡ 1.0ï¼ˆéå¸¸å¤§å£°ï¼‰ï¼Œç›´æ¥å½’ä¸€åŒ–åˆ° 1.0
        if power >= 1.0 {
            return 1.0
        }

        // 4. æŒ‰æ¯”ä¾‹çº¿æ€§æ˜ å°„åˆ° 0~1
        return (abs(minDb) - abs(power)) / abs(minDb)
    }

    func setCategory(_ active: Bool = true,
                     _ category: AVAudioSession.Category = .playback,
                     mode: AVAudioSession.Mode = .default) {
        let session = AVAudioSession.sharedInstance()

        do {
            if active {
                if category == .playAndRecord {
                    try session.setCategory(category,
                                            mode: mode,
                                            options: [
                                                .defaultToSpeaker,
                                                .allowBluetoothHFP,
                                                .allowBluetoothA2DP,
                                            ])
                } else {
                    try session.setCategory(category,
                                            mode: mode,
                                            options: [
                                                .allowBluetoothHFP,
                                                .allowBluetoothA2DP,
                                            ])
                }
            }

            try session.setActive(active, options: .notifyOthersOnDeactivation)
            try session.overrideOutputAudioPort(.speaker)

            if let inputs = AVAudioSession.sharedInstance().availableInputs {
                if let bluetooth = inputs.first(where: { $0.portType == .bluetoothHFP }) {
                    try AVAudioSession.sharedInstance().setPreferredInput(bluetooth)
                }
            }
        } catch {
            NLog.error("è®¾ç½®setActiveå¤±è´¥ï¼š", error.localizedDescription)
        }
    }

    func requestMicrophonePermission() {
        AVAudioSession.sharedInstance().requestRecordPermission { granted in
            self.hasMicrophonePermission = granted
        }
    }

    @objc private func handleInterruption(_ notification: Notification) {
        guard let userInfo = notification.userInfo,
              let typeValue = userInfo[AVAudioSessionInterruptionTypeKey] as? UInt,
              let type = AVAudioSession.InterruptionType(rawValue: typeValue) else {
            return
        }

        switch type {
        case .began:
            // ä¸­æ–­å¼€å§‹ï¼Œæ¯”å¦‚ç”µè¯è¿›æ¥ -> æš‚åœæ’­æ”¾
            NLog.log("ğŸ”´ éŸ³é¢‘è¢«æ‰“æ–­ï¼ˆå¼€å§‹ï¼‰")
            sessionInterrupted?(.begin)
            // åœ¨è¿™é‡Œæš‚åœæ’­æ”¾å™¨
            return

        case .ended:
            // ä¸­æ–­ç»“æŸï¼Œå¯ä»¥æ¢å¤æ’­æ”¾
            NLog.log("ğŸŸ¢ éŸ³é¢‘æ‰“æ–­ç»“æŸ")
            // ç³»ç»Ÿä¼šå‘Šè¯‰ä½ æ˜¯å¦å¯ä»¥æ¢å¤
            if let optionsValue = userInfo[AVAudioSessionInterruptionOptionKey] as? UInt {
                let options = AVAudioSession.InterruptionOptions(rawValue: optionsValue)
                if options.contains(.shouldResume) {
                    // æ¢å¤æ’­æ”¾
                    NLog.log("âœ… å¯ä»¥æ¢å¤æ’­æ”¾")
                    sessionInterrupted?(.resume)
                    return
                }
            }
            sessionInterrupted?(.end)
            return
        @unknown default:
            sessionInterrupted?(.other)

            return
        }
    }
}

enum InterruptedType {
    case begin
    case end
    case resume
    case other
}
